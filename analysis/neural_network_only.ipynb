{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tfidf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "from DSI_Capstone_Steemit.utils.utils import(\n",
    "    load_data_and_description,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "data_directory = '../data/'\n",
    "input_directory = os.path.join(data_directory,'networkx_votes')\n",
    "\n",
    "def load_joblib(filename):\n",
    "    return joblib.load(os.path.join(input_directory,filename))\n",
    "\n",
    "data,feature_names,data_desc = load_data_and_description(data_type='tfidf')\n",
    "data_desc['log total_payout_value'] = np.log(data_desc['total_payout_value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_network_features(df):\n",
    "\n",
    "    hubs,authorities = load_joblib('hits')\n",
    "    cluster = load_joblib('parts')\n",
    "    pagerank = load_joblib('prank') \n",
    "    eig_cent = load_joblib('eig_cent') \n",
    "    core_k = load_joblib('core_k') \n",
    "\n",
    "    df['Cluster'] = df['author'].map(cluster)\n",
    "    df.loc[:,'Cluster Condense'] = df['Cluster']\n",
    "    df.loc[~df['Cluster'].isin([1,3,0,2,5,4]),'Cluster Condense'] = 'Other'\n",
    "    df['Hubs'] = df['author'].map(hubs) * 10000\n",
    "    df['Authorities'] = df['author'].map(authorities) * 10000\n",
    "    df['Page Rank'] = df['author'].map(pagerank) * 10000\n",
    "    df['Eigen Centrality'] = df['author'].map(eig_cent)* 10000\n",
    "    df['Core K'] = df['author'].map(core_k)*10000\n",
    "    return df\n",
    "data_desc = add_network_features(data_desc)\n",
    "\n",
    "network_cols = ['Page Rank','Cluster','Hubs','Authorities','Page Rank','Eigen Centrality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remove middle value articles\n",
    "\n",
    "idx1 = data_desc['log total_payout_value'] < 1.2\n",
    "idx2 = data_desc['log total_payout_value'] >2.5\n",
    "\n",
    "idx_not = (~idx1) & (~idx2)\n",
    "\n",
    "data_desc = data_desc[~idx_not]\n",
    "data = data[~idx_not.values,:]\n",
    "y = data_desc['log total_payout_value'] >2.5\n",
    "\n",
    "# For Regression\n",
    "# y = data_desc['log total_payout_value']\n",
    "value_counts = data_desc['category'].value_counts()\n",
    "top_categories = value_counts.index[value_counts > np.percentile(data_desc['category'].value_counts(),97)]\n",
    "idx = data_desc['category'].isin(top_categories)\n",
    "data_desc['top category'] = idx.astype(int)\n",
    "\n",
    "data_desc['top category listed'] = data_desc.ix[data_desc['top category'].values.astype(bool) ,'category']\n",
    "\n",
    "data_desc['top category listed'] = data_desc['top category listed'].fillna('Other')\n",
    "\n",
    "\n",
    "post_features = ['number of body tags',\n",
    "                                   'number of body urls',\n",
    "                                   'number of image urls',\n",
    "                                   'number of body mentions',\n",
    "                                   'number of image urls',\n",
    "                                   'number of youtube urls',\n",
    "                                   'language',\n",
    "                                   'author_reputation_scaled',\n",
    "                                   'number of steem counts',\n",
    "                                'top category'] + network_cols\n",
    "\n",
    "\n",
    "train_features = data_desc.ix[:,post_features].fillna(0)\n",
    "\n",
    "train = pd.get_dummies(train_features,columns=['language','Cluster'])\n",
    "\n",
    "num_image_urls = train['number of image urls'].values[:,0]\n",
    "train.drop('number of image urls',axis = 1, inplace=True)\n",
    "\n",
    "train['number of image urls'] = num_image_urls\n",
    "\n",
    "training_names = train.columns\n",
    "\n",
    "train_sparse = ssp.csr_matrix(train)\n",
    "new_data = ssp.hstack([data,train_sparse])\n",
    "train = new_data.tocsr()\n",
    "\n",
    "# All samples\n",
    "number_of_samples = train.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'number of body tags', u'number of body urls',\n",
       "       u'number of body mentions', u'number of youtube urls',\n",
       "       u'author_reputation_scaled', u'number of steem counts', u'top category',\n",
       "       u'Page Rank', u'Hubs', u'Authorities',\n",
       "       ...\n",
       "       u'Cluster_5', u'Cluster_7', u'Cluster_10', u'Cluster_11', u'Cluster_27',\n",
       "       u'Cluster_33', u'Cluster_78', u'Cluster_85', u'Cluster_218',\n",
       "       u'number of image urls'],\n",
       "      dtype='object', length=114)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56905, 21378)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# samples = X_train\n",
    "X = X_train.toarray()#[0:samples]\n",
    "y = y_train.astype(int).values#[0:samples]\n",
    "# y = keras.utils.np_utils.to_categorical(y)\n",
    "\n",
    "\n",
    "\n",
    "X_val = X_test.toarray()#[0:samples]\n",
    "\n",
    "y_val = y_test.astype(int).values#[0:samples]\n",
    "# y_val = keras.utils.np_utils.to_categorical(y_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "2  0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_val).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [    1     4     9 ..., 21341 21348 21374] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "f_values = f_classif(X,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values,pvalues = f_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:1: RuntimeWarning: invalid value encountered in less\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "idx = (pvalues < 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'academia', u'adventure', u'ai', u'alcohol', u'alien',\n",
       "       u'allasyummyfood', u'amsterdam', u'anarchism', u'anarchy',\n",
       "       u'animal', u'anyxphotos', u'architecture', u'art', u'artwork',\n",
       "       u'astronomy', u'australia', u'author', u'autism', u'badge', u'bali',\n",
       "       u'banking', u'basketball', u'beach', u'berlin', u'better',\n",
       "       u'beyondbitcoin', u'biology', u'bitcoin', u'bittrex', u'blog',\n",
       "       u'book', u'boutique', u'brain', u'bravenewcoin', u'breakfast',\n",
       "       u'bsotn', u'burstcoin', u'business', u'ca', u'casa', u'cervantes',\n",
       "       u'chemistry', u'chemistry-lesson', u'chemtrails', u'chinadaily',\n",
       "       u'chocolate', u'christ', u'cn-qap', u'cn-stats', u'coding',\n",
       "       u'coffee', u'cognitive-biases', u'comment', u'compassion',\n",
       "       u'computer', u'consciousness', u'contest', u'cooking', u'craft',\n",
       "       u'craigrant', u'creative', u'creativity', u'crisis',\n",
       "       u'crowdfundedwhale', u'crypto-news', u'cryptocurrency', u'culture',\n",
       "       u'curation', u'curators-wanted', u'curie', u'cxjhj', u'cyberfund',\n",
       "       u'dailyquotes', u'dailysteemart', u'dao', u'dapp', u'developer',\n",
       "       u'diet', u'digitalart', u'disruptmeister', u'diy', u'doyourpart',\n",
       "       u'drawing', u'dream', u'economics', u'education', u'emotion',\n",
       "       u'energy', u'engineering', u'entertainment', u'entrepreneur',\n",
       "       u'entrepreneurship', u'environment', u'esteem', u'ethereum',\n",
       "       u'evolution', u'factorysteemit', u'family', u'fanart', u'fantasy',\n",
       "       u'farm', u'fear', u'fiction', u'film', u'fire', u'flight', u'food',\n",
       "       u'foodchallenge', u'foodporn', u'football', u'fossil',\n",
       "       u'fotografia', u'fractal', u'fraud', u'fredrikstad', u'futbol',\n",
       "       u'future', u'gamble', u'gaming', u'garden', u'gardening',\n",
       "       u'general', u'german', u'ghostwriter', u'girlspower', u'giveaway',\n",
       "       u'golos', u'good-curators', u'gourmet', u'government', u'guild',\n",
       "       u'halloween', u'handmade', u'happiness', u'health',\n",
       "       u'healthyliving', u'heartgoodnesschallenge', u'herpetology',\n",
       "       u'hiking', u'history', u'holi-art', u'homeless', u'horror',\n",
       "       u'house-market', u'howto', u'humor', u'illuminati', u'illustration',\n",
       "       u'innovation', u'inspiration', u'introduceyourself',\n",
       "       u'investigative-journalism', u'investment', u'italy', u'japan',\n",
       "       u'jardin', u'journal', u'katecloud', u'knozaki2015', u'kr',\n",
       "       u'kr-curieweekly', u'landscape', u'laoyao', u'latte-art', u'law',\n",
       "       u'leaderboards', u'legend', u'liberty', u'life', u'lifestyle',\n",
       "       u'lighttheworld', u'literature', u'love', u'macro', u'manga',\n",
       "       u'mar', u'marijuana', u'marketplace', u'marriage', u'math',\n",
       "       u'medicine', u'meetup', u'meme', u'mexico', u'millionaire',\n",
       "       u'mindfulness', u'minnowsunite', u'minnowsunited', u'money',\n",
       "       u'motivation', u'motivational', u'motocross', u'movie',\n",
       "       u'movie-review', u'moviereview', u'mushroom', u'music', u'nano',\n",
       "       u'nature', u'nevergetbusted', u'new', u'news', u'newslink',\n",
       "       u'newyork', u'nfl', u'nonfiction', u'novel', u'nsfw', u'nyc',\n",
       "       u'oculus', u'oneironautics', u'openledger', u'openmic',\n",
       "       u'operational-update', u'origami', u'originalmusic',\n",
       "       u'originalwork', u'osc', u'outdoors', u'owner', u'ozchartart',\n",
       "       u'painting', u'panama', u'parenting', u'parody', u'peerplays',\n",
       "       u'permacryptofolio', u'permaculture', u'pevo', u'pfunkblog',\n",
       "       u'pfunkphotos', u'philosophy', u'photography', u'photojournalism',\n",
       "       u'physic', u'piscina', u'piston', u'playoff', u'poetry',\n",
       "       u'poloniex', u'popularscience', u'portrait', u'positivity',\n",
       "       u'pregnancydiary', u'programming', u'project-curie', u'psychology',\n",
       "       u'racism', u'radiosteem', u'ramtasnakk', u'random', u'reality',\n",
       "       u'recipe', u'recycle', u'relationship', u'reptile', u'research',\n",
       "       u'review', u'roadtrip', u'robotev', u'robotics', u'rockstar',\n",
       "       u'rome', u'russian', u'rusteemitblog', u'safecrack', u'sbd',\n",
       "       u'scam', u'scary', u'science', u'sciencefiction', u'scifi',\n",
       "       u'secret-writer', u'self-help', u'self-improvement',\n",
       "       u'sirwinchester', u'sister', u'sketch', u'slavery', u'smallpost',\n",
       "       u'soccer', u'soccer-sweepstakes', u'society', u'songofera',\n",
       "       u'space', u'spam', u'spanish', u'spelunking', u'spider',\n",
       "       u'sponsored', u'sport', u'spreadthepower', u'star-wars', u'statism',\n",
       "       u'stats', u'steem', u'steem-bot', u'steem-guild', u'steem-life',\n",
       "       u'steem-marketing', u'steem-meme', u'steem-saturday',\n",
       "       u'steemadvent', u'steemb', u'steembets', u'steemclean',\n",
       "       u'steemcleaners', u'steememe', u'steemenomics', u'steemfest',\n",
       "       u'steemfest-reconnect', u'steemforchange', u'steemgirls',\n",
       "       u'steemguild', u'steemit', u'steemit-book-club', u'steemit-bot',\n",
       "       u'steemit-health', u'steemit-ideas', u'steemit4free',\n",
       "       u'steemitbookclub', u'steemitcryptochallenge', u'steemittugofwar',\n",
       "       u'steemitworldlottery', u'steemizen', u'steemmobile',\n",
       "       u'steemocracy', u'steemsanta', u'steemsmartpodcast', u'steemsports',\n",
       "       u'steemsports-soccer', u'steemsquad', u'steemstats', u'steemstem',\n",
       "       u'steemthought', u'steemtrail', u'steemvoter', u'stemmit', u'story',\n",
       "       u'success', u'surfing', u'sustainability', u'synereo',\n",
       "       u'taskmanager', u'tattoo', u'technical-analysis', u'technology',\n",
       "       u'test', u'thecryptodrive', u'thedailypic', u'til', u'tip', u'toy',\n",
       "       u'trading', u'travel', u'trevonjb', u'tribune', u'tutorial',\n",
       "       u'usesteem', u'ussr', u'vaccine', u'vaxxed', u'veganism',\n",
       "       u'videogames', u'voluntaryism', u'voting', u'wellbeing', u'whale',\n",
       "       u'winter', u'witness-category', u'witness-update', u'writer',\n",
       "       u'yoga', u'zcash', u'number of body tags',\n",
       "       u'number of youtube urls', u'author_reputation_scaled',\n",
       "       u'top category', u'Page Rank', u'Hubs', u'Authorities',\n",
       "       u'Page Rank', u'Eigen Centrality', u'language_da', u'language_en',\n",
       "       u'language_es', u'language_ko', u'language_no', u'language_ru',\n",
       "       u'language_unknown', u'Cluster_0', u'Cluster_1', u'Cluster_2',\n",
       "       u'Cluster_3', u'Cluster_4', u'number of image urls'], \n",
       "      dtype='<U88')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = np.array(feature_names + list(training_names))\n",
    "all_features[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val = X_val[:,idx]\n",
    "X = X[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56905, 396)\n",
      "(28029, 396)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Params testing: ', {'lr': 0.07438498681878454})\n",
      "Epoch 1/10\n",
      "56905/56905 [==============================] - 17s - loss: 2.1480    \n",
      "Epoch 2/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.7301    \n",
      "Epoch 3/10\n",
      "56905/56905 [==============================] - 19s - loss: 0.7115    \n",
      "Epoch 4/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.7144    \n",
      "Epoch 5/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.7125    \n",
      "Epoch 6/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.7073    \n",
      "Epoch 7/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.7004    \n",
      "Epoch 8/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.6976    \n",
      "Epoch 9/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.6954    \n",
      "Epoch 10/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.6947    \n",
      "('Accuracy:', 0.51097078026329867)\n",
      "('Params testing: ', {'lr': 0.07652653327619954})\n",
      "Epoch 1/10\n",
      "56905/56905 [==============================] - 19s - loss: 6.9336    \n",
      "Epoch 2/10\n",
      "56905/56905 [==============================] - 18s - loss: 6.4234    \n",
      "Epoch 3/10\n",
      "56905/56905 [==============================] - 17s - loss: 6.3581    \n",
      "Epoch 4/10\n",
      "56905/56905 [==============================] - 17s - loss: 3.1050    \n",
      "Epoch 5/10\n",
      "56905/56905 [==============================] - 18s - loss: 1.1548    \n",
      "Epoch 6/10\n",
      "56905/56905 [==============================] - 19s - loss: 0.7778    \n",
      "Epoch 7/10\n",
      "56905/56905 [==============================] - 19s - loss: 0.7885    \n",
      "Epoch 8/10\n",
      "56905/56905 [==============================] - 19s - loss: 0.7641    \n",
      "Epoch 9/10\n",
      "56905/56905 [==============================] - 20s - loss: 0.7572    \n",
      "Epoch 10/10\n",
      "56905/56905 [==============================] - 18s - loss: 0.7523    \n",
      "('Accuracy:', 0.51097078026329867)\n",
      "('Params testing: ', {'lr': 0.0824617800009953})\n",
      "Epoch 1/10\n",
      "56905/56905 [==============================] - 19s - loss: 4.9779    \n",
      "Epoch 2/10\n",
      "56905/56905 [==============================] - 19s - loss: 1.2046    \n",
      "Epoch 3/10\n",
      "56905/56905 [==============================] - 19s - loss: 0.8420    \n",
      "Epoch 4/10\n",
      "56905/56905 [==============================] - 19s - loss: 0.7821    \n",
      "Epoch 5/10\n",
      "56905/56905 [==============================] - 21s - loss: 0.7664    \n",
      "Epoch 6/10\n",
      "56905/56905 [==============================] - 21s - loss: 0.7380    \n",
      "Epoch 7/10\n",
      "56905/56905 [==============================] - 20s - loss: 0.7237    \n",
      "Epoch 8/10\n",
      "35456/56905 [=================>............] - ETA: 8s - loss: 0.7205"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-bb2738f35d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'best: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-bb2738f35d53>\u001b[0m in \u001b[0;36mf_nn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mpred_auc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import log_loss, roc_auc_score,accuracy_score\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta, Adam, rmsprop\n",
    "\n",
    "\n",
    "space = {\n",
    "        'lr': hp.uniform('lr', 0.0001,0.1),\n",
    "}\n",
    "\n",
    "dropout = 0.5\n",
    "def f_nn(params):   \n",
    "\n",
    "    print ('Params testing: ', params)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim=1000, input_dim = X.shape[1])) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    model.add(Dense(output_dim=500))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(output_dim=100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(output_dim=10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.adagrad(params['lr']))\n",
    "\n",
    "    model.fit(X, y, nb_epoch=10, batch_size=32, verbose = 1)\n",
    "\n",
    "    pred_auc =model.predict_classes(X_val, batch_size = 32, verbose = 0)\n",
    "    acc = accuracy_score(y_val, pred_auc)\n",
    "    \n",
    "    print('Accuracy:', acc)\n",
    "    sys.stdout.flush() \n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=25, trials=trials)\n",
    "print 'best: '\n",
    "print best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "56905/56905 [==============================] - 9s - loss: 1.8666     \n",
      "Epoch 2/3\n",
      "56905/56905 [==============================] - 8s - loss: 0.6850     \n",
      "Epoch 3/3\n",
      "56905/56905 [==============================] - 9s - loss: 0.6708     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x391937ad0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim=500, input_dim = X.shape[1])) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "model.add(Dense(output_dim=250))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(output_dim=100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.adagrad(0.034118198130292786))\n",
    "\n",
    "model.fit(X, y, nb_epoch=3, batch_size=32, verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65546398373113557"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
