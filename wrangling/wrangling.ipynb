{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/posts_tfidf\n",
      "../data/posts_counts\n",
      "../data/word2vec_doc_matrix_avg\n",
      "../data/word2vec_doc_matrix_avg_tfidf\n",
      "../data/posts_raw_cleaned\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_directory = os.path.join(os.getcwd().split('DSI_Capstone_Steemit')[0])\n",
    "sys.path.insert(1,module_directory)\n",
    "\n",
    "from DSI_Capstone_Steemit.utils.utils import(\n",
    "    ensure_directories\n",
    ")\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "dir_list = ['posts_tfidf',\n",
    "            'posts_counts',\n",
    "            'word2vec_doc_matrix_avg',\n",
    "            'word2vec_doc_matrix_avg_tfidf',\n",
    "           'posts_raw_cleaned']\n",
    "ensure_directories(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module_directory = os.path.join(os.getcwd().split('DSI_Capstone_Steemit')[0])\n",
    "sys.path.insert(1,module_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import DSI_Capstone_Steemit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "data_directory = '../data/'\n",
    "\n",
    "posts_path = os.path.join(data_directory,'sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_posts = pd.read_csv(posts_path)\n",
    "# Remove all unicode related characters\n",
    "df_posts['body'] = df_posts['body'].str.decode('unicode_escape').str.encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine multiple updates to articles to get one body per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_body = df_posts.groupby(['author','permlink']).agg(lambda x: ''.join(set(x))).reset_index()\n",
    "combined_bFody = combined_body.ix[:,['body','author','permlink']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates, due to multiple updates, then combine with full body text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove Duplicates\n",
    "idx_not_duplicates = ~df_posts.duplicated(['author','permlink'])\n",
    "df_posts = df_posts.ix[idx_not_duplicates,:]\n",
    "df_posts.drop('body',axis = 1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_posts = pd.merge(df_posts,combined_body,on=['author','permlink'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_posts.sort_values(by='total_payout_value',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expression = r'http\\S+'\n",
    "\n",
    "# Extract all Links\n",
    "df_posts['body urls'] = df_posts['body'].str.findall(expression)\n",
    "df_posts['number of body urls'] = df_posts['body urls'].apply(len)\n",
    "df_posts['number of youtube urls'] = (df_posts.ix[:,'body urls']\n",
    "                                      .str.join(' ')\n",
    "                                      .str.replace('\\.','')\n",
    "                                      .str.count('youtube'))\n",
    "\n",
    "df_posts['number of image urls'] = (df_posts.ix[:,'body urls']\n",
    "                                    .str.join(' ')\n",
    "                                    .str.count('jpg|png|gif|jpeg'))\n",
    "\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "# Remove Hashtags\n",
    "expression = '#(\\S+)'\n",
    "# Extract all Hash Tages\n",
    "df_posts['body tags'] = df_posts['body'].str.findall(expression)\n",
    "df_posts['number of body tags'] = df_posts['body tags'].apply(len)\n",
    "\n",
    "# Remove all Tags\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "\n",
    "# Remove Mentions : @thecryptodrive\n",
    "expression = '@(\\S+)'\n",
    "# Extract all Hash Tages\n",
    "df_posts['body mentions'] = df_posts['body'].str.findall(expression)\n",
    "df_posts['number of body mentions'] = df_posts['body mentions'].apply(len)\n",
    "\n",
    "# Remove all Tags\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "\n",
    "\n",
    "# Remove all Links\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "\n",
    "# Remove all periods\n",
    "expression = '\\.'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,' ')\n",
    "\n",
    "# # Remove all new lines\n",
    "expression = r'\\n'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,' ')\n",
    "\n",
    "\n",
    "# These can probably be removed\n",
    "# # Extract/Remove Markdown Related for Headers\n",
    "# expression = '0A0A(.*?)0A0A'\n",
    "# df_posts['body headers'] = df_posts['body'].str.findall(expression)\n",
    "\n",
    "\n",
    "# # Extract/Remove Markdown Related for Code\n",
    "# expression = '60(.*?)60'\n",
    "# df_posts['body code'] = df_posts['body'].str.findall(expression)\n",
    "\n",
    "# expression = '\\d+'\n",
    "# df_posts['body'] = df_posts['body'].str.replace(expression,' ')\n",
    "\n",
    "\n",
    "\n",
    "# Remove Any Capital Letter by themselves A, B, C, D etc\n",
    "expression = r'\\b[A-Z]\\b'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "\n",
    "# Remove double spaces\n",
    "expression = ' +'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,' ')\n",
    "\n",
    "# Remove pure numerical values that have greater than 5 digits\n",
    "expression = r'\\b[0-9]{5,100}\\b'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "\n",
    "# Remove all non alpha numeric\n",
    "expression = '[^A-Za-z0-9 ]+'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,'')\n",
    "\n",
    "expression = '0A0A'\n",
    "df_posts['body'] = df_posts['body'].str.replace(expression,' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_posts['body'] = df_posts['body'].str.decode('unicode_escape').str.encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   a look   Update 3 More shortterm fixes for the weekendtesters  5B201607235D5Bbf3dae55D 7C 5Bsetup5D make sure the user uses python30A 5B201607235D5Bc31eec75D 7C 5Bweb5D highlight own posts0A 5B201607235D5B03e0d2f5D 7C 5Bweb5D fix reply identifier not in the form   wn risk   Update 1 Id like to clarify that this GUI is not meant to replace steemit com or be used as a hosted public site It rather offers a personal localhostonly page that you can use to access your wallet Exposing the piston web to a publicly accessible port is not recommended imgsafe org2411b61f27 png Piston web Standalone User Interface Many may already know piston as a tool that simplifies interaction with SteemSteemit You can read post comment edit transfer funds and much more if you are willing to use the command line This changes now With piston web the toolbox now comes with graphical user interface that you can access via your browser It is fully independent of steemit com which means that you can do what you love doing on Steem even if steemit com goes down Available Features browsing steem posts reading full posts and comments reply to topics and comments upvotedownvote read account details recommended posts blog posts funds transaction history integrated wallet full encrypted AES BIP32 for private keys import keys from account name and password Screenshots Browse imgsafe org219c17ace1 png Account imgsafe org219c1dbdc5 png Funds imgsafe org219c2ae8a0 png Post imgsafe org219c26f1d0 png Wallet imgsafe org219c2e7b58 png Installation Until we leave prealpha piston web is on a different branch git checkout featurestandaloneweb make installuser install extra requirements for piston web pip install r requirementsweb txt Usage piston web On first run you will be asked to provide a passphrase for your new wallet Empty password are allowed but result in private keys being stored in plain text After that you will see Running on 0 0  Press CTRL to quit Restarting with stat Debugger is active Debugger pin code  Ignore the debugging output and start using piston web in your browser by accessing 0 0  NOTE piston web will only be reachable from the same machine localhost Technologies Backend The backend is written in python using Flask with Jinja2 pythonsteem It offers the HTML files and a SocketIO for realtime communications Frontend These technologies have been used so far in piston web Bootstrap Markdown FontAwesome Plain Javascript Wallet The wallet is only accessible from the backend All keys are encrypted with a random master password that is stored in an SQLite3 database in its AES encrypted form Each private key is encrypted with the master password using BIP32 and stored in a SQLite3 database The wallet will make backups of the SQLite3 database every week and keep several weeks of backup Todos Transfer of funds PowerUp PowerDown Trading Account Administration changing keys etc Allow to attach JSON object to posts Secure socket io with a password layout and style improvements Contributions Currently we are looking for the bravest of the bravest to help us test what is already there and give bug reports improvement proposals feature request Please use the github issue tracker comxerocpistonissues to make it easier for us to remember all the feedback Important Note piston web is alpha software For that reason you need to expect it to break at any time Use at your own risk   piston0A cd piston0A git   ranch   git clone comxerocpiston0A git   mmended   Update 2 I fixed the 60sqlite3 OperationalError unable to open database file60 error earlier today so that people can actually take a look '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts.ix[0,'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts_raw_cleaned = os.path.join(data_directory,\n",
    "                                             'posts_raw_cleaned', \n",
    "                                             'posts_raw_cleaned.csv')\n",
    "\n",
    "\n",
    "df_posts.to_csv(posts_raw_cleaned,\n",
    "                              index=False, \n",
    "                              quoting=csv.QUOTE_ALL, \n",
    "                              encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save Word Counts, TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "porter =  PorterStemmer()\n",
    "class PorterTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.porter = porter.stem\n",
    "    def __call__(self, doc):\n",
    "        return [self.porter(t) for t in word_tokenize(doc)]\n",
    "\n",
    "countvect = CountVectorizer(\n",
    "    encoding = 'utf-8',\n",
    "    tokenizer = PorterTokenizer(),\n",
    "    stop_words = stopwords.words('english'),\n",
    "    lowercase = False\n",
    "    \n",
    ")\n",
    "\n",
    "tfidfvect = TfidfVectorizer(\n",
    "    encoding = 'utf-8',\n",
    "    tokenizer = PorterTokenizer(),\n",
    "    stop_words = stopwords.words('english'),\n",
    "    lowercase = False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_counts = countvect.fit_transform(df_posts['body'])\n",
    "posts_tfidf = tfidfvect.fit_transform(df_posts['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_counts_path = os.path.join(data_directory,'posts_counts', 'posts_counts')\n",
    "posts_tfidf_path = os.path.join(data_directory,'posts_tfidf', 'posts_tfidf')\n",
    "\n",
    "joblib.dump(posts_counts,posts_counts_path)\n",
    "joblib.dump(countvect.get_feature_names(),posts_counts_path+'_feature_names')\n",
    "\n",
    "joblib.dump(posts_tfidf,posts_tfidf_path)\n",
    "joblib.dump(tfidfvect.get_feature_names(),posts_tfidf_path+'_feature_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_posts.shape, posts_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data that goes with counts and vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_posts.drop('body',axis = 1,inplace=True)\n",
    "\n",
    "posts_counts_desc_path = os.path.join(data_directory,\n",
    "                                             'posts_counts', \n",
    "                                             'posts_counts_desc.csv')\n",
    "\n",
    "\n",
    "df_posts.to_csv(posts_counts_desc_path,\n",
    "                              index=False, \n",
    "                              quoting=csv.QUOTE_ALL, \n",
    "                              encoding='utf-8')\n",
    "\n",
    "posts_tfidf_desc_path = os.path.join(data_directory,\n",
    "                                             'posts_tfidf', \n",
    "                                             'posts_tfidf_desc.csv')\n",
    "\n",
    "\n",
    "df_posts.to_csv(posts_tfidf_desc_path,\n",
    "                              index=False, \n",
    "                              quoting=csv.QUOTE_ALL, \n",
    "                              encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
